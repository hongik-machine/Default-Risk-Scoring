"""
Baseline preprocessing helpers aligned with the sample logistic+SMOTE script.

ì œê³µ ê¸°ëŠ¥:
- load_table: CSV/XLS/XLSX ì½ê¸°
- split_data: í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬ (stratify ì˜µì…˜)
- build_numeric_preprocessor: SimpleImputer(median) + StandardScaler
- fit_transform_preprocessor / transform_preprocessor: ì „ì²˜ë¦¬ í—¬í¼
- smote_resample: (í•™ìŠµì…‹ í•œì •) SMOTE ì ìš©
- make_pipeline: [preprocess] -> [model]  (ìƒ˜í”Œê³¼ ë™ì¼í•˜ê²Œ SMOTEëŠ” íŒŒì´í”„ë¼ì¸ ë°–ì—ì„œ)

â€» ì „ì œ: í”¼ì²˜ê°€ ì „ë¶€ ìˆ«ì(UCI Default ë°ì´í„°ì²˜ëŸ¼)ë¼ëŠ” ê°€ì •.
   ë²”ì£¼í˜•ì´ ìƒê¸°ë©´ OneHot í˜¹ì€ SMOTENCë¡œ í™•ì¥ í•„ìš”.
"""
from __future__ import annotations
import numpy as np
import pandas as pd
from typing import Optional, List, Union
from enum import Enum, auto
from dataclasses import dataclass, field

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import (
    OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler
)
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.base import TransformerMixin, BaseEstimator

from imblearn.over_sampling import SMOTENC


# =========================================================
# Scaling ì „ëµ Enum
# =========================================================
class ScalingStrategy(Enum):
    STANDARD = auto()  # Logistic Regression, SVM
    MINMAX = auto()  # Neural Network, Deep Learning
    ROBUST = auto()  # Outlier-resistant
    NONE = auto()  # Tree-based models


# =========================================================
# ì „ì²˜ë¦¬ ì˜µì…˜ dataclass
# =========================================================
@dataclass
class PreprocessConfig:
    use_payment_status_mapping: bool = True
    payment_status_as_categorical: bool = False
    # ë¦¬ìŠ¤íŠ¸ ê¸°ë³¸ê°’ì€ field(default_factory=list)ë¡œ ì„¤ì •í•´ì•¼ ì•ˆì •ì ì…ë‹ˆë‹¤.
    force_categorical: Optional[List[str]] = field(default_factory=list)
    outlier_clip: bool = True
    scaling_strategy: ScalingStrategy = ScalingStrategy.ROBUST


# =========================================================
# 1. íŒŒì¼ ë¡œë”
# =========================================================
def load_table(path: str, *, sheet_name: Optional[str] = None, **kwargs) -> pd.DataFrame:
    low = path.lower()
    if low.endswith(".csv"):
        return pd.read_csv(path, **kwargs)
    if low.endswith(".xls") or low.endswith(".xlsx"):
        return pd.read_excel(path, sheet_name=sheet_name, **kwargs)
    raise ValueError(f"Unsupported file format: {path}")


# =========================================================
# 2. ì»¬ëŸ¼ íƒ€ì… ìë™ ê°ì§€
# =========================================================
def detect_feature_types(df: pd.DataFrame, force_categorical: Optional[List[str]] = None):
    num = df.select_dtypes(include=[np.number]).columns.tolist()
    cat = df.select_dtypes(include=["object"]).columns.tolist()

    if force_categorical:
        for c in force_categorical:
            if c in num:
                num.remove(c)
            # ìˆ«ìë¡œ ë§¤í•‘ëœ ë²”ì£¼í˜•ë„ 'object'ê°€ ì•„ë‹Œ 'number'ë¡œ ê°ì§€ë˜ë¯€ë¡œ,
            # ê°•ì œë¡œ ë²”ì£¼í˜•ìœ¼ë¡œ ì·¨ê¸‰í•´ì•¼ í•  ê²½ìš°, numì—ì„œ ì œê±°í•˜ê³  catì— ì¶”ê°€.
            if c not in cat:
                cat.append(c)

    # ì¤‘ë³µ ì œê±° ë° ìµœì¢… í™•ì •
    num = list(set(num))
    cat = list(set(cat))
    return num, cat


# =========================================================
# 3. payment_status ë§¤í•‘ (Ordinal ì²˜ë¦¬ ë° ê²°ì¸¡ì¹˜ ëª…í™•í™”) ğŸŒŸ ê°œì„ 
# =========================================================
def map_payment_status(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:
    mapping = {
        "Payed duly": 0,
        "Payment delayed 1 month": 1,
        "Payment delayed 2 months": 2,
        "Payment delayed 3 months": 3,
        "Payment delayed 4 months": 4,
        "Payment delayed 5 months": 5,
        "Payment delayed 6 months": 6,
        "Unknown": -1,
    }

    df = df.copy()
    for c in cols:
        if c in df.columns:
            df[c] = df[c].map(mapping)
            # 'Unknown'(-1)ì„ ëª…ì‹œì ìœ¼ë¡œ np.nanìœ¼ë¡œ ë³€í™˜í•˜ì—¬
            # ì´í›„ SimpleImputer(median/mode)ê°€ ì²˜ë¦¬í•˜ë„ë¡ í•¨.
            df[c] = df[c].replace(-1, np.nan)
    return df


# =========================================================
# 4. IQR ê¸°ë°˜ outlier clipping ğŸŒŸ ê°œì„ 
# =========================================================
def clip_outliers(df: pd.DataFrame, cols: List[str], factor=1.5) -> pd.DataFrame:
    df = df.copy()
    for col in cols:
        # ë°ì´í„°ì— ê²°ì¸¡ì¹˜ê°€ ìˆì„ ê²½ìš°, quantile ê³„ì‚° ì „ì— ë¬´ì‹œ (Imputerê°€ ì²˜ë¦¬ ì˜ˆì •)
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - factor * IQR
        upper = Q3 + factor * IQR

        # ì›ë˜ ë°ì´í„° íƒ€ì… ì €ì¥ (í´ë¦¬í•‘ í›„ ì •ìˆ˜í˜• ë³µì› ìœ„í•¨)
        original_dtype = df[col].dtype

        df[col] = df[col].clip(lower, upper)

        # ì›ë˜ dtypeì´ ì •ìˆ˜í˜• ê³„ì—´ì´ì—ˆìœ¼ë©´, floatë¡œ ë³€í™˜ëœ ê°’ì„ ë‹¤ì‹œ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³µì›
        if pd.api.types.is_integer_dtype(original_dtype) or original_dtype == np.int64:
            # í´ë¦¬í•‘ëœ ê°’ì€ ì‹¤ìˆ˜í˜•ì´ ë˜ì—ˆì„ ìˆ˜ ìˆì§€ë§Œ, round í›„ ì •ìˆ˜ë¡œ ë³µì› (NaNì€ ìœ ì§€)
            df[col] = df[col].round().astype(original_dtype, errors="ignore")
    return df


# =========================================================
# 5. Train/Test split
# =========================================================
def split_data(X, y, *, test_size=0.2, stratify=True, random_state=42):
    return train_test_split(
        X, y,
        test_size=test_size,
        stratify=y if stratify else None,
        random_state=random_state
    )


# =========================================================
# 6. Train/Val/Test split
# =========================================================
def three_way_split(
        X, y,
        *, test_size=0.2, val_size=0.2,
        stratify=True, random_state=42
):
    X_train, X_temp, y_train, y_temp = train_test_split(
        X, y,
        test_size=(test_size + val_size),
        stratify=y if stratify else None,
        random_state=random_state
    )

    rel_test = test_size / (test_size + val_size)

    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp,
        test_size=rel_test,
        stratify=y_temp if stratify else None,
        random_state=random_state
    )

    return X_train, X_val, X_test, y_train, y_val, y_test


# =========================================================
# 7. SMOTENC (OneHot ì´ì „ ë‹¨ê³„ì—ì„œ ì‹¤í–‰)
# =========================================================
def smote_before_encoding(
        df: pd.DataFrame,
        target_col: str,
        categorical_cols: List[str],
        numerical_cols: List[str],
        *,
        random_state=42,
        k_neighbors=5
):
    df = df.copy()

    X = df[categorical_cols + numerical_cols]
    # SMOTENCëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ê°€ ì •ìˆ˜í˜•ì´ì–´ì•¼ í•¨ (object/strëŠ” ë¶ˆê°€ëŠ¥)
    y = df[target_col].astype(int)

    classes, counts = np.unique(y, return_counts=True)
    minority = counts.min()

    if minority < 2:
        print("[WARN] Minority class < 2 â†’ SMOTE ë¶ˆê°€ëŠ¥. ì›ë³¸ ë°ì´í„° ë°˜í™˜.")
        return df

    # k_neighbors ì¡°ì •
    k_neighbors = max(1, min(k_neighbors, minority - 1))

    # SMOTENCëŠ” ê²°ì¸¡ì¹˜ë¥¼ í—ˆìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì„ì‹œë¡œ ìµœë¹ˆê°’/ì¤‘ì•™ê°’ ëŒ€ì²´ í›„ SMOTE ì ìš©
    temp_X = X.copy()
    for col in categorical_cols:
        temp_X[col] = temp_X[col].fillna(temp_X[col].mode()[0])
    for col in numerical_cols:
        temp_X[col] = temp_X[col].fillna(temp_X[col].median())

    cat_indices = [temp_X.columns.get_loc(c) for c in categorical_cols]

    smote = SMOTENC(
        categorical_features=cat_indices,
        random_state=random_state,
        k_neighbors=k_neighbors
    )

    X_res, y_res = smote.fit_resample(temp_X, y)  # ì„ì‹œ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©

    X_res = pd.DataFrame(X_res, columns=X.columns)
    y_res = pd.Series(y_res, name=target_col)

    # SMOTE í›„ ê²°ì¸¡ì¹˜ ì¬ë„ì…: SMOTEê°€ ê²°ì¸¡ì¹˜ë¥¼ í¬í•¨í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë¥¼ ìƒì„±í–ˆìœ¼ë¯€ë¡œ,
    # ì´ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , ì´í›„ ColumnTransformerì—ì„œ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ë¥¼ ì§„í–‰.

    return pd.concat([X_res, y_res], axis=1)


# =========================================================
# 8. ColumnTransformer êµ¬ì„±
# =========================================================
def build_preprocessor(
        X: pd.DataFrame,
        config: Optional[PreprocessConfig] = None
):
    if config is None:
        config = PreprocessConfig()
    df = X.copy()

    # -------------------------------------------
    # payment_status ì»¬ëŸ¼ ì²˜ë¦¬
    # -------------------------------------------
    ps_cols = [c for c in df.columns if "payment_status" in c]

    if config.use_payment_status_mapping:
        # map_payment_status í•¨ìˆ˜ ë‚´ì—ì„œ -1ì´ np.nanìœ¼ë¡œ ë³€í™˜ë¨
        df = map_payment_status(df, ps_cols)

        if config.payment_status_as_categorical:
            # ê°•ì œë¡œ ë²”ì£¼í˜•ìœ¼ë¡œ ì·¨ê¸‰í•˜ë„ë¡ force_categoricalì— ì¶”ê°€
            if config.force_categorical is None:
                config.force_categorical = []
            config.force_categorical += ps_cols

    # -------------------------------------------
    # ì»¬ëŸ¼ íƒ€ì… ê°ì§€
    # -------------------------------------------
    num_cols, cat_cols = detect_feature_types(df, config.force_categorical)

    # -------------------------------------------
    # Outlier clipping
    # -------------------------------------------
    if config.outlier_clip:
        df = clip_outliers(df, num_cols)

    # -------------------------------------------
    # ìŠ¤ì¼€ì¼ëŸ¬ ì„ íƒ
    # -------------------------------------------
    if config.scaling_strategy == ScalingStrategy.STANDARD:
        scaler = StandardScaler()
    elif config.scaling_strategy == ScalingStrategy.MINMAX:
        scaler = MinMaxScaler()
    elif config.scaling_strategy == ScalingStrategy.ROBUST:
        scaler = RobustScaler()
    else:
        scaler = "passthrough"

    # -------------------------------------------
    # ê°ê°ì˜ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
    # -------------------------------------------
    numeric_pipeline = Pipeline([
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬: Outlier clipping í›„ ë°œìƒí•  ìˆ˜ ìˆëŠ” nanê³¼ ì›ë˜ nan ì²˜ë¦¬
        ("impute", SimpleImputer(strategy="median")),
        ("scale", scaler)
    ])

    categorical_pipeline = Pipeline([
        ("impute", SimpleImputer(strategy="most_frequent")),
        # handle_unknown="ignore"ëŠ” ìƒˆë¡œìš´ ë²”ì£¼ ë“±ì¥ ì‹œ ì—ëŸ¬ ëŒ€ì‹  0 ë²¡í„° ë°˜í™˜
        ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
    ])

    # -------------------------------------------
    # ColumnTransformer ì¡°ë¦½
    # -------------------------------------------
    preprocessor = ColumnTransformer(
        transformers=[
            ("num", numeric_pipeline, num_cols),
            ("cat", categorical_pipeline, cat_cols)
        ],
        remainder="passthrough",  # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ì€ ê·¸ëŒ€ë¡œ í†µê³¼(passthrough)
        verbose_feature_names_out=True
    )

    return preprocessor, df


# =========================================================
# 9. ì „ì²˜ë¦¬ + ëª¨ë¸ Pipeline
# =========================================================
def build_full_pipeline(model: Union[BaseEstimator, TransformerMixin], preprocessor: ColumnTransformer) -> Pipeline:
    return Pipeline([
        ("preprocess", preprocessor),
        ("model", model)
    ])


# =========================================================
# 10. ë³€í™˜ëœ í”¼ì²˜ ì´ë¦„ í—¬í¼ í•¨ìˆ˜ ğŸŒŸ ì¶”ê°€
# =========================================================
def get_transformed_feature_names(preprocessor: ColumnTransformer) -> List[str]:
    """
    ColumnTransformerë¥¼ í†µê³¼í•œ í›„ì˜ ìµœì¢… í”¼ì²˜ ì´ë¦„ ëª©ë¡ì„ ë°˜í™˜í•œë‹¤.
    (One-Hot Encodingìœ¼ë¡œ ì¸í•´ ëŠ˜ì–´ë‚œ í”¼ì²˜ ì´ë¦„ í¬í•¨)
    """
    return list(preprocessor.get_feature_names_out())